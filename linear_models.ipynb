{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c8edd",
   "metadata": {},
   "outputs": [],
   "source": [
    " %pip install numpy pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899de0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ffb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need synthetic data\n",
    "\n",
    "n = 100\n",
    "rng = np.random.default_rng()\n",
    "X = 2*rng.random((n,1)) # input features\n",
    "y = 4 + 3*X + rng.normal(0,1,(n,1)) # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6db50fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(X,y,\"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a93573d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99814602, 1.        ],\n",
       "       [0.00859072, 1.        ],\n",
       "       [1.63026678, 1.        ],\n",
       "       [1.05077476, 1.        ],\n",
       "       [1.05358362, 1.        ],\n",
       "       [1.47106633, 1.        ],\n",
       "       [0.37536329, 1.        ],\n",
       "       [1.57399305, 1.        ],\n",
       "       [1.10096801, 1.        ],\n",
       "       [0.17457355, 1.        ],\n",
       "       [1.64232023, 1.        ],\n",
       "       [1.44398277, 1.        ],\n",
       "       [1.25383573, 1.        ],\n",
       "       [1.94549496, 1.        ],\n",
       "       [1.05191497, 1.        ],\n",
       "       [0.70846871, 1.        ],\n",
       "       [0.97377753, 1.        ],\n",
       "       [0.89968127, 1.        ],\n",
       "       [0.07184961, 1.        ],\n",
       "       [1.13082487, 1.        ],\n",
       "       [1.08725891, 1.        ],\n",
       "       [1.38481069, 1.        ],\n",
       "       [0.94838189, 1.        ],\n",
       "       [1.05846006, 1.        ],\n",
       "       [1.14743213, 1.        ],\n",
       "       [0.01286128, 1.        ],\n",
       "       [0.16823592, 1.        ],\n",
       "       [0.0693514 , 1.        ],\n",
       "       [0.4124447 , 1.        ],\n",
       "       [1.25970672, 1.        ],\n",
       "       [0.05799639, 1.        ],\n",
       "       [1.27818185, 1.        ],\n",
       "       [0.7914802 , 1.        ],\n",
       "       [1.76481888, 1.        ],\n",
       "       [0.74713088, 1.        ],\n",
       "       [1.5575843 , 1.        ],\n",
       "       [0.08837857, 1.        ],\n",
       "       [1.81233911, 1.        ],\n",
       "       [0.35599815, 1.        ],\n",
       "       [0.43422968, 1.        ],\n",
       "       [0.58815216, 1.        ],\n",
       "       [1.62339894, 1.        ],\n",
       "       [1.15966009, 1.        ],\n",
       "       [0.57083583, 1.        ],\n",
       "       [0.19367072, 1.        ],\n",
       "       [1.79033595, 1.        ],\n",
       "       [0.98054122, 1.        ],\n",
       "       [0.91404293, 1.        ],\n",
       "       [0.92793653, 1.        ],\n",
       "       [1.13058844, 1.        ],\n",
       "       [0.37759477, 1.        ],\n",
       "       [1.0232485 , 1.        ],\n",
       "       [1.65849287, 1.        ],\n",
       "       [0.95029385, 1.        ],\n",
       "       [1.44302458, 1.        ],\n",
       "       [0.3341706 , 1.        ],\n",
       "       [1.92606541, 1.        ],\n",
       "       [1.37572987, 1.        ],\n",
       "       [0.01619222, 1.        ],\n",
       "       [1.15044341, 1.        ],\n",
       "       [0.74164071, 1.        ],\n",
       "       [0.1316519 , 1.        ],\n",
       "       [1.55317295, 1.        ],\n",
       "       [0.93090831, 1.        ],\n",
       "       [0.43617934, 1.        ],\n",
       "       [0.72921191, 1.        ],\n",
       "       [1.82303019, 1.        ],\n",
       "       [1.12321449, 1.        ],\n",
       "       [0.57291093, 1.        ],\n",
       "       [1.26208478, 1.        ],\n",
       "       [1.10814864, 1.        ],\n",
       "       [1.84964821, 1.        ],\n",
       "       [0.73215331, 1.        ],\n",
       "       [1.35109751, 1.        ],\n",
       "       [1.53212139, 1.        ],\n",
       "       [1.17542224, 1.        ],\n",
       "       [1.66818415, 1.        ],\n",
       "       [0.39536681, 1.        ],\n",
       "       [1.77592828, 1.        ],\n",
       "       [0.37917387, 1.        ],\n",
       "       [1.08316365, 1.        ],\n",
       "       [1.78329933, 1.        ],\n",
       "       [1.95688111, 1.        ],\n",
       "       [0.27074121, 1.        ],\n",
       "       [0.33197346, 1.        ],\n",
       "       [0.60718625, 1.        ],\n",
       "       [0.99819693, 1.        ],\n",
       "       [1.41184622, 1.        ],\n",
       "       [1.00220354, 1.        ],\n",
       "       [0.93176937, 1.        ],\n",
       "       [0.33464999, 1.        ],\n",
       "       [0.84316253, 1.        ],\n",
       "       [1.07620151, 1.        ],\n",
       "       [1.49546283, 1.        ],\n",
       "       [0.12144054, 1.        ],\n",
       "       [0.96535543, 1.        ],\n",
       "       [1.13898788, 1.        ],\n",
       "       [1.40229435, 1.        ],\n",
       "       [0.79871237, 1.        ],\n",
       "       [1.11116596, 1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b = np.hstack([X, np.ones((n,1))]) # design matrix -> first example of feature engineering\n",
    "X_b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d89a169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.87507554],\n",
       "       [4.12391064]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "w_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2fd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0,1], [2,1]])\n",
    "#use model equation\n",
    "\n",
    "y_pred = X_new @ w_best\n",
    "plt.figure()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef9071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "879bf9e4",
   "metadata": {},
   "source": [
    "Batch Gradient Descent\n",
    "Loss Function\n",
    "Gradient Descent Update Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c5741",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha= 0.1 #learning rate, number between 0 and 1, mostly very close to zero\n",
    "epochs= 20 #its around 20 to 500\n",
    "           #1 epochs= the algorithm visted whole dataset 1 time\n",
    "\n",
    "w_bdg = rng.random((2,1))\n",
    "\n",
    "for epochs in range(epochs):#training loop\n",
    "#compute gradients\n",
    "    gradients = 2 / n * X_b.T @ (X_b @ w_bdg - y) #X_b @ w_bgd = y_hat\n",
    "    #\n",
    "y_pred = X_new @ w_bdg\n",
    "plt.figure()\n",
    "plt.plot(X_new[:0], y_pred, \"r-\")\n",
    "plt.plot(X,y, \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afbf93",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8117d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha= 0.01 #learning rate, number between 0 and 1, mostly very close to zero\n",
    "epochs= 100\n",
    "\n",
    "w_bdg = rng.random((2,1))\n",
    "\n",
    "for epochs in range(epochs):\n",
    "    for iter in range(n):\n",
    "        random_index = rng.integers(0,n)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        #compute gradients\n",
    "        gradients = 2  * X_b.T @ (xi @ w_bdg - yi) \n",
    "        #apply the rule\n",
    "        w_sgd = w_sgd - alpha*gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa270d29",
   "metadata": {},
   "source": [
    "Mini-Batch Gradients Desent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha= 0.01 #learning rate, number between 0 and 1, mostly very close to zero\n",
    "epochs= 100\n",
    "B= 8 #batch size\n",
    "\n",
    "w_mbdg = rng.random((2,1))\n",
    "\n",
    "for epochs in range(epochs):\n",
    "    for iter in range(n):\n",
    "        random_index = rng.integers(0,n-B)\n",
    "        xi = X_b[random_index:random_index+B]\n",
    "        yi = y[random_index:random_index+B]\n",
    "        #compute gradients\n",
    "        gradients = 2  * xi.T @ (xi @ w_bdg - yi) \n",
    "        #apply the rule\n",
    "        w_mbgd = w_mbgd - alpha*gradients\n",
    "\n",
    "w_mbgd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7bc36",
   "metadata": {},
   "source": [
    "# Logistic Regression via minimization of negative log likehood using Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5c0d2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.13/site-packages (4.5.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from datasets) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.13/site-packages (from datasets) (2.4.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.13/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./.venv/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.13/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in ./.venv/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in ./.venv/lib/python3.13/site-packages (from datasets) (1.3.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d520e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (2.4.1)\n",
      "Requirement already satisfied: scipy>=1.10.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e8490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "131a533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sms', 'label'],\n",
       "        num_rows: 5574\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"sms_spam\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f02420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"label\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0075ae79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"sms\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "217922c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"label\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f5036da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms1= \"large string\"\n",
    "sms2= \"second large string\"\n",
    "sms3= \"third very large string\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a61561",
   "metadata": {},
   "source": [
    "| x | large | string | second | third | very | Type |\n",
    "|---|-------|--------|--------|-------|------|------|\n",
    "| sms1 | 1 | 1 | 0 | 0 | 0 | binary |\n",
    "| sms2 | 1 | 1 | 1 | 0 | 0 | binary |\n",
    "| sms3 | 1 | 1 | 1 | 1 | 2 | binary |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ab0da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b53a8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000, binary=True)\n",
    "X_train = vectorizer.fit_transform([x[\"sms\"] for x in X[\"train\"]]).toarray()\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d1147cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '04', '0800', '08000839402', '08000930705', '10', '100',\n",
       "       '1000', '10p', '11', '11mths', '12', '12hrs', '150', '150p',\n",
       "       '150ppm', '16', '18', '1st', '20', '200', '2000', '2003', '20p',\n",
       "       '250', '2day', '2lands', '2nd', '2nite', '30', '350', '4u', '50',\n",
       "       '500', '5000', '750', '800', '8007', '86688', '87066', 'abiola',\n",
       "       'able', 'about', 'abt', 'account', 'actually', 'add', 'address',\n",
       "       'aft', 'after', 'afternoon', 'again', 'against', 'age', 'age16',\n",
       "       'ago', 'ah', 'aight', 'all', 'almost', 'alone', 'already',\n",
       "       'alright', 'also', 'always', 'am', 'amp', 'an', 'and', 'angry',\n",
       "       'another', 'answer', 'any', 'anyone', 'anything', 'anytime',\n",
       "       'anyway', 'apartment', 'apply', 'ard', 'are', 'area', 'around',\n",
       "       'as', 'ask', 'askd', 'asked', 'asking', 'ass', 'at', 'attempt',\n",
       "       'auction', 'available', 'await', 'award', 'awarded', 'away',\n",
       "       'awesome', 'b4', 'babe', 'baby', 'back', 'bad', 'balance', 'bank',\n",
       "       'be', 'beautiful', 'because', 'bed', 'been', 'before', 'being',\n",
       "       'believe', 'best', 'better', 'between', 'big', 'birthday', 'bit',\n",
       "       'bonus', 'book', 'booked', 'bored', 'both', 'bout', 'box', 'boy',\n",
       "       'boytoy', 'break', 'bring', 'brother', 'bslvyl', 'bt', 'bus',\n",
       "       'busy', 'but', 'buy', 'by', 'call', 'call2optout', 'called',\n",
       "       'caller', 'calling', 'calls', 'camcorder', 'came', 'camera', 'can',\n",
       "       'cancel', 'cant', 'car', 'card', 'care', 'carlos', 'case', 'cash',\n",
       "       'cause', 'chance', 'change', 'charge', 'charged', 'chat', 'check',\n",
       "       'checking', 'chennai', 'chikku', 'choose', 'christmas', 'claim',\n",
       "       'class', 'close', 'club', 'co', 'code', 'coffee', 'collect',\n",
       "       'collection', 'college', 'colour', 'com', 'come', 'comes', 'comin',\n",
       "       'coming', 'comp', 'company', 'complete', 'complimentary',\n",
       "       'computer', 'confirm', 'congrats', 'congratulations', 'contact',\n",
       "       'content', 'cool', 'copy', 'correct', 'cos', 'cost', 'could',\n",
       "       'couple', 'course', 'coz', 'crave', 'credit', 'cs', 'cum',\n",
       "       'currently', 'customer', 'da', 'dad', 'darlin', 'darren', 'dat',\n",
       "       'date', 'dating', 'day', 'days', 'de', 'dear', 'decided',\n",
       "       'decimal', 'deep', 'delivery', 'den', 'details', 'did', 'didn',\n",
       "       'didnt', 'die', 'different', 'difficult', 'dinner', 'direct',\n",
       "       'dis', 'discount', 'disturb', 'dnt', 'do', 'does', 'doesn', 'doin',\n",
       "       'doing', 'don', 'done', 'dont', 'door', 'double', 'down', 'draw',\n",
       "       'dream', 'dreams', 'drink', 'drive', 'driving', 'drop', 'dude',\n",
       "       'dun', 'dunno', 'during', 'each', 'earlier', 'early', 'easy',\n",
       "       'eat', 'eh', 'either', 'else', 'email', 'end', 'ends', 'enjoy',\n",
       "       'enough', 'enter', 'entered', 'entry', 'etc', 'eve', 'even',\n",
       "       'evening', 'ever', 'every', 'everyone', 'everything', 'ex', 'exam',\n",
       "       'expires', 'extra', 'face', 'family', 'fancy', 'fantastic', 'far',\n",
       "       'fast', 'feel', 'feeling', 'felt', 'few', 'figure', 'film',\n",
       "       'final', 'finally', 'find', 'fine', 'fingers', 'finish',\n",
       "       'finished', 'first', 'fone', 'food', 'for', 'forget', 'forgot',\n",
       "       'found', 'fr', 'free', 'freemsg', 'fri', 'friday', 'friend',\n",
       "       'friends', 'friendship', 'frm', 'frnd', 'frnds', 'from', 'fuck',\n",
       "       'fucking', 'full', 'fun', 'game', 'games', 'gas', 'gave', 'gd',\n",
       "       'ge', 'get', 'gets', 'getting', 'getzed', 'gift', 'girl', 'girls',\n",
       "       'give', 'glad', 'gn', 'go', 'god', 'goes', 'goin', 'going', 'gone',\n",
       "       'gonna', 'good', 'goodmorning', 'got', 'gotta', 'gr8', 'great',\n",
       "       'gt', 'guaranteed', 'gud', 'guess', 'guy', 'guys', 'gym', 'ha',\n",
       "       'had', 'haf', 'haha', 'hair', 'half', 'hand', 'happen', 'happened',\n",
       "       'happiness', 'happy', 'hard', 'has', 'hav', 'have', 'haven',\n",
       "       'havent', 'having', 'he', 'head', 'hear', 'heard', 'heart', 'hee',\n",
       "       'hello', 'help', 'her', 'here', 'hey', 'hg', 'hi', 'him', 'his',\n",
       "       'hit', 'hiya', 'hmm', 'hmmm', 'hold', 'holiday', 'home', 'hope',\n",
       "       'hot', 'hour', 'hours', 'house', 'how', 'hows', 'http', 'huh',\n",
       "       'hurt', 'ice', 'id', 'identifier', 'if', 'ill', 'im',\n",
       "       'immediately', 'important', 'in', 'india', 'info', 'information',\n",
       "       'into', 'invited', 'ipod', 'is', 'isn', 'it', 'its', 'itself',\n",
       "       'jay', 'job', 'join', 'jus', 'just', 'juz', 'keep', 'kind', 'kiss',\n",
       "       'knew', 'know', 'knows', 'knw', 'land', 'landline', 'laptop',\n",
       "       'lar', 'last', 'late', 'later', 'latest', 'lazy', 'least', 'leave',\n",
       "       'leaves', 'leaving', 'left', 'leh', 'lei', 'less', 'lesson', 'let',\n",
       "       'lets', 'liao', 'life', 'light', 'like', 'line', 'link', 'listen',\n",
       "       'little', 'live', 'll', 'loads', 'loan', 'log', 'lol', 'long',\n",
       "       'look', 'looking', 'lor', 'lose', 'lost', 'lot', 'lots', 'love',\n",
       "       'loved', 'lovely', 'loving', 'lt', 'ltd', 'lucky', 'lunch', 'luv',\n",
       "       'made', 'mah', 'mail', 'make', 'makes', 'making', 'man', 'many',\n",
       "       'march', 'match', 'mate', 'mates', 'may', 'mayb', 'maybe', 'me',\n",
       "       'mean', 'means', 'meant', 'meet', 'meeting', 'merry', 'message',\n",
       "       'messages', 'met', 'might', 'min', 'mind', 'mine', 'mins',\n",
       "       'minute', 'minutes', 'miss', 'missed', 'missing', 'mm', 'mo',\n",
       "       'mob', 'mobile', 'mobiles', 'mobileupd8', 'mom', 'moment', 'money',\n",
       "       'month', 'moral', 'more', 'morning', 'most', 'motorola', 'movie',\n",
       "       'mr', 'mrng', 'msg', 'msgs', 'mu', 'much', 'mum', 'music', 'must',\n",
       "       'muz', 'my', 'na', 'nah', 'name', 'national', 'need', 'needs',\n",
       "       'net', 'network', 'neva', 'never', 'new', 'news', 'next', 'ni8',\n",
       "       'nice', 'night', 'nite', 'no', 'noe', 'nokia', 'nope', 'normal',\n",
       "       'not', 'nothing', 'now', 'nt', 'ntt', 'number', 'numbers', 'nyt',\n",
       "       'of', 'off', 'offer', 'offers', 'office', 'oh', 'ok', 'okay',\n",
       "       'okie', 'old', 'on', 'once', 'one', 'online', 'only', 'oops',\n",
       "       'open', 'operator', 'opt', 'or', 'orange', 'orchard', 'order',\n",
       "       'oredi', 'oso', 'other', 'our', 'out', 'outside', 'over', 'own',\n",
       "       'pa', 'pain', 'parents', 'park', 'part', 'party', 'pass', 'pay',\n",
       "       'people', 'per', 'person', 'pete', 'phone', 'phones', 'pic',\n",
       "       'pick', 'picking', 'pics', 'place', 'plan', 'plans', 'play',\n",
       "       'player', 'please', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox',\n",
       "       'point', 'points', 'poly', 'poor', 'post', 'pound', 'pounds',\n",
       "       'pray', 'press', 'pretty', 'price', 'princess', 'private', 'prize',\n",
       "       'prob', 'probably', 'problem', 'project', 'pub', 'put', 'question',\n",
       "       'questions', 'quite', 'quiz', 'rain', 'rakhesh', 'rate', 'rates',\n",
       "       're', 'reach', 'reached', 'read', 'reading', 'ready', 'real',\n",
       "       'really', 'reason', 'receive', 'redeemed', 'remember', 'remove',\n",
       "       'rent', 'reply', 'representative', 'request', 'rest', 'right',\n",
       "       'ring', 'ringtone', 'ringtones', 'rite', 'room', 'row', 'rply',\n",
       "       'rs', 'run', 'sad', 'sae', 'safe', 'said', 'same', 'sat',\n",
       "       'saturday', 'save', 'saw', 'say', 'saying', 'says', 'sch',\n",
       "       'school', 'sea', 'search', 'second', 'secret', 'see', 'seeing',\n",
       "       'seen', 'selected', 'sell', 'semester', 'send', 'sending', 'sent',\n",
       "       'service', 'services', 'set', 'sex', 'sexy', 'shall', 'she',\n",
       "       'shit', 'shop', 'shopping', 'short', 'should', 'show', 'shower',\n",
       "       'shows', 'sick', 'side', 'since', 'sir', 'sis', 'sister',\n",
       "       'situation', 'sleep', 'sleeping', 'slow', 'small', 'smile',\n",
       "       'smiling', 'smoke', 'sms', 'smth', 'snow', 'so', 'some',\n",
       "       'somebody', 'someone', 'something', 'somewhere', 'song', 'soon',\n",
       "       'sorry', 'sounds', 'speak', 'special', 'spend', 'start', 'started',\n",
       "       'starting', 'statement', 'stay', 'std', 'still', 'stop', 'store',\n",
       "       'story', 'study', 'stuff', 'stupid', 'sub', 'suite342', 'sun',\n",
       "       'sunday', 'support', 'supposed', 'sure', 'surprise', 'sweet',\n",
       "       'swing', 'take', 'takes', 'taking', 'talk', 'talking', 'tampa',\n",
       "       'tc', 'tell', 'ten', 'terms', 'test', 'text', 'texts', 'th',\n",
       "       'than', 'thank', 'thanks', 'thanx', 'that', 'thats', 'the',\n",
       "       'their', 'them', 'then', 'there', 'these', 'they', 'thing',\n",
       "       'things', 'think', 'thinking', 'thinks', 'this', 'thk', 'tho',\n",
       "       'those', 'though', 'thought', 'through', 'til', 'till', 'time',\n",
       "       'times', 'tired', 'tmr', 'to', 'today', 'todays', 'together',\n",
       "       'told', 'tomo', 'tomorrow', 'tone', 'tones', 'tonight', 'too',\n",
       "       'took', 'top', 'tot', 'touch', 'town', 'train', 'treat', 'tried',\n",
       "       'trip', 'true', 'truth', 'try', 'trying', 'ts', 'tv', 'two', 'txt',\n",
       "       'txting', 'txts', 'type', 'ugh', 'uk', 'un', 'understand',\n",
       "       'unless', 'unlimited', 'unsubscribe', 'until', 'up', 'update',\n",
       "       'ur', 'urgent', 'urself', 'us', 'use', 'used', 'user', 'usf',\n",
       "       'using', 'usual', 'valid', 'valued', 've', 'very', 'via', 'video',\n",
       "       'visit', 'voucher', 'vouchers', 'w1j6hl', 'wait', 'waiting',\n",
       "       'wake', 'walk', 'wan', 'wanna', 'want', 'wanted', 'wants', 'warm',\n",
       "       'was', 'wat', 'watch', 'watching', 'water', 'way', 'we', 'weed',\n",
       "       'week', 'weekend', 'weekly', 'weeks', 'welcome', 'well', 'wen',\n",
       "       'went', 'were', 'what', 'whatever', 'whats', 'when', 'whenever',\n",
       "       'where', 'which', 'while', 'who', 'whole', 'why', 'wid', 'wif',\n",
       "       'wife', 'wil', 'will', 'win', 'wine', 'winner', 'wish', 'wishing',\n",
       "       'wit', 'with', 'within', 'without', 'wk', 'wkly', 'won', 'wonder',\n",
       "       'wonderful', 'wont', 'word', 'words', 'work', 'working', 'world',\n",
       "       'worry', 'worth', 'wot', 'would', 'wow', 'write', 'wrong', 'www',\n",
       "       'xmas', 'xx', 'xxx', 'ya', 'yar', 'yeah', 'year', 'years', 'yep',\n",
       "       'yes', 'yesterday', 'yet', 'yo', 'you', 'your', 'yours',\n",
       "       'yourself', 'yr', 'yup'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3d1ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000, binary=True)\n",
    "X_train = vectorizer.fit_transform([x[\"sms\"] for x in X[\"train\"]]).toarray()\n",
    "X_test = vectorizer.fit_transform([x[\"sms\"] for x in X[\"test\"]]).toarray()\n",
    "y_train = [x[\"label\"] for x in X[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in X[\"test\"]]\n",
    "X_test[0]\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b8fe473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "X_train_np = X_train.astype(np.float32)\n",
    "X_test_np = X_test.astype(np.float32)\n",
    "y_train_np = np.asarray(y_train, dtype=np.float32)\n",
    "y_test_np = np.asarray(y_test, dtype=np.float32)\n",
    " \n",
    "# Add bias term (intercept)\n",
    "X_train_b = np.hstack([np.ones((X_train_np.shape[0], 1), dtype=np.float32), X_train_np])\n",
    "X_test_b = np.hstack([np.ones((X_test_np.shape[0], 1), dtype=np.float32), X_test_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): #it was our rho\n",
    "    return 1/(1+ np.exp(-z))\n",
    "\n",
    "def negative_log_likehood(y,p):\n",
    "    eps = 1e-8\n",
    "    return (-1)*(y*np.log(p) + (1-y)*np.log(1-p + eps))\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "w_mbgd = rng.normal(size=X_train_b.shape[1]).astype(np.float32)\n",
    "\n",
    "# TUDO Train mbgd\n",
    "alpha= 0.01 #learning rate, number between 0 and 1, mostly very close to zero\n",
    "epochs= 1000\n",
    "B= 64 #batch size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(n):\n",
    "        random_index = rng.integers(0,n-B)\n",
    "        xi = X_train_brandom_index:random_index+B]\n",
    "        yi = y_train_np[random_index:random_index+B]\n",
    "        #compute gradients\n",
    "        logits\n",
    "        gradients = 2  * xi.T @ (xi @ w_bdg - yi) \n",
    "        #apply the rule\n",
    "        w_mbgd = w_mbgd - alpha*gradients\n",
    "\n",
    "w_mbgd\n",
    "# model\n",
    "\n",
    "z = w_mbgd.T @ X_test_b[0] #logit = number before sigmoid\n",
    "prob = sigmoid(z) #probability\n",
    "dec = \"SPAM\" if prob > 0.5 else \"NO SPAM\" #decision\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994d3a6",
   "metadata": {},
   "source": [
    "# Never do this(data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, binary=True)\n",
    "X_f = vectorizer.fit_transform([x[\"sms\"] for x in dataset[\"train\"]]).toarray()\n",
    "X_train_f, X_test_f = train_test_split(X_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a439b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
