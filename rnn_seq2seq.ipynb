{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54fcf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"I am a boy.\"\n",
    "target = \"I ch bin ein Junge.\"\n",
    "\n",
    "# -----------\n",
    "#Encoder [\"I am a boy.\"] ->\n",
    "# Next Token Prediction\n",
    "# 1. step Decoder [h, <bos>] -> \"ich\"\n",
    "# 2. step Decoder [h, (<bos>, \"ich\")] -> \"bin\"\n",
    "# 3. step Decoder [h, (<bos>, \"ich\", \"bin\")] -> \"ein\"\n",
    "# 4. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\")] -> \"Junge\"\n",
    "# 5. step Decoder [h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\")] -> \"<eos>\"\n",
    "\n",
    "# X = (h, (<bos>, \"ich\", \"bin\", \"ein\", \"Junge\" )) -> Input for Decoder\n",
    "# y = (\"ich\", \"bin\", \"ein\", \"Junge\", <eos>) -> target/labels for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f0d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, json, torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "path = \"./deu.txt\"\n",
    " \n",
    "lines = open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "lines = lines[:20000]\n",
    " \n",
    "pairs = [ln.split(\"\\t\")[:2] for ln in lines] \n",
    "src_texts, tgt_texts = zip(*pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0500d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, UNK, BOS, EOS = 0, 1, 2, 3 # special tokens\n",
    "# PAD = Padding, UNK = Unknown\n",
    "# BOS, EOS\n",
    "\n",
    "VOCAB_SIZE = 20004\n",
    "\n",
    "def tokenize(s): return re.findall(r\"\\b\\w+\\b\", s.lower())\n",
    "def build_vocab(texts, max_tokens=VOCAB_SIZE):\n",
    "    from collections import Counter\n",
    "    freq = Counter(tok for t in texts for tok in tokenize(t))\n",
    "    itos = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"] + [w for w,_ in freq.most_common(max_tokens-4)]\n",
    "    return {w:i for i,w in enumerate(itos)}, itos\n",
    "src_texts_vocab, src_itos = build_vocab(src_texts)\n",
    "tgt_texts_vocab, tgt_itos = build_vocab(tgt_texts)\n",
    "\n",
    "\n",
    "def vectorize(text, stoi, max_len, add_bos_eos=False):\n",
    "    ids = [stoi.get(tok, UNK) for tok in tokenize(text)]\n",
    "    if add_bos_eos: ids = [BOS] + ids + [EOS]\n",
    "    ids = ids[:max_len]\n",
    "    if len(ids) < max_len: ids += [PAD]*(max_len-len(ids))\n",
    "    return ids\n",
    "\n",
    "vectorize(src_texts[60], src_texts_vocab, 30)\n",
    "\n",
    "\n",
    "max_src, max_tgt = 30, 30  \n",
    " \n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src = torch.tensor([vectorize(t, src_texts_vocab, max_src) for t in src_batch])\n",
    "    tgt = torch.tensor([vectorize(t, tgt_texts_vocab, max_tgt, add_bos_eos=True) for t in tgt_batch])\n",
    "    tgt_in, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "    return src, tgt_in, tgt_out\n",
    " \n",
    "dataset = list(zip(src_texts, tgt_texts))\n",
    "loader = DataLoader(dataset, batch_size= 64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa22f271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_texts_vocab) #number of \n",
    "len(tgt_texts_vocab) #number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4be383b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': 0, 'is': 1, 'of': 2, 'sample': 3, 'sentence': 4, 'this': 5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"this is sample sentence of embedding\"\n",
    "setence2 = \"this is sentence embedding\" \n",
    "\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581f75ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8064, -2.6200, -1.1094],\n",
       "        [ 0.6000,  0.7072,  1.1946],\n",
       "        [-0.6399, -1.8828,  1.0682],\n",
       "        [-0.3114, -0.7501,  0.4061],\n",
       "        [ 0.0199,  0.5681, -0.1465],\n",
       "        [ 0.6575,  0.0779,  1.1704]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_tmp = len(dc)\n",
    "emb = torch.nn.Embedding(vocab_size_tmp, 3)\n",
    "emb.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884a2ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq25Seq(\n",
       "  (enc): Encoder(\n",
       "    (embedding): Embedding(3455, 128, padding_idx=0)\n",
       "    (rnn): GRU(128, 256, batch_first=True)\n",
       "  )\n",
       "  (dec): Decoder(\n",
       "    (embedding): Embedding(5594, 128, padding_idx=0)\n",
       "    (rnn): GRU(128, 256, batch_first=True)\n",
       "    (fc): Linear(in_features=256, out_features=5594, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 128\n",
    "hid_dim = 256\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.add_module(\"rnn\", nn.GRU(emb_dim,hid_dim,batch_first=True))\n",
    "    def forward(self, src):\n",
    "        x = self.embedding(src)\n",
    "        _, hidden = self.rnn(x)\n",
    "        return hidden\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD)\n",
    "        self.add_module(\"rnn\", nn.GRU(emb_dim,hid_dim,batch_first=True))\n",
    "        self.fc = nn.Linear(hid_dim, vocab_size)\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        out, _= self.rnn(x,h)\n",
    "        return self.fc(out)\n",
    "        \n",
    "class Seq25Seq(nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    \n",
    "    def forward(self, src, tgt_in_dec):\n",
    "        # src ... source (english sentences)\n",
    "        # tgt_in_dec ... actual german sentences that are also input to the decoder\n",
    "        hidden_enc = self.enc(src)\n",
    "        logits = self.dec(tgt_in_dec, hidden_enc)\n",
    "        return logits\n",
    "    \n",
    "device = \"mps\"\n",
    "\n",
    "model = Seq25Seq(\n",
    "    Encoder(len(src_texts_vocab)),\n",
    "    Decoder(len(tgt_texts_vocab))\n",
    ").to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3416f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: loss 4.4135\n",
      "ich bin ein buch\n",
      "epoch 2: loss 3.2131\n",
      "ich habe das gesagt\n",
      "epoch 3: loss 2.6003\n",
      "ich habe mich geirrt\n",
      "epoch 4: loss 2.1796\n",
      "ich habe mein buch\n",
      "epoch 5: loss 1.8581\n",
      "ich werde mein auto holen\n",
      "epoch 6: loss 1.5962\n",
      "ich werde mein auto holen\n",
      "epoch 7: loss 1.3697\n",
      "ich werde mein bestes\n",
      "epoch 8: loss 1.1729\n",
      "ich werde mein bestes\n",
      "epoch 9: loss 1.0044\n",
      "ich werde mein bestes\n",
      "epoch 10: loss 0.8599\n",
      "ich werde mein bestes\n",
      "epoch 11: loss 0.7351\n",
      "ich werde mein bestes\n",
      "epoch 12: loss 0.6337\n",
      "ich bin mein eigener chef\n",
      "epoch 13: loss 0.5480\n",
      "ich werde mein bestes\n",
      "epoch 14: loss 0.4832\n",
      "ich werde mein bestes\n",
      "epoch 15: loss 0.4295\n",
      "ich werde mein bestes geben\n",
      "epoch 16: loss 0.3865\n",
      "ich werde mein bestes\n",
      "epoch 17: loss 0.3520\n",
      "ich werde mein bestes geben\n",
      "epoch 18: loss 0.3272\n",
      "ich bin mein eigener chef\n",
      "epoch 19: loss 0.3077\n",
      "ich bin wie in ordnung\n",
      "epoch 20: loss 0.2923\n",
      "ich werde mein bestes geben\n"
     ]
    }
   ],
   "source": [
    "crit = nn.CrossEntropyLoss(ignore_index=PAD) #padding is an artificial token and it keeps the sequence long\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n",
    "epochs = 20\n",
    "\n",
    "@torch.no_grad()\n",
    "def translate(prompt, max_len=max_tgt):\n",
    "    model.eval()\n",
    "    src = torch.tensor([vectorize(prompt, src_texts_vocab, max_src)], device=device)\n",
    "    h = model.enc(src)\n",
    "    ys = torch.tensor([[BOS]], device=device)\n",
    "    out_tokens = []\n",
    "    for _ in range(max_len):\n",
    "        logits = model.dec(ys, h)\n",
    "        next_id = logits[0, -1].argmax().item()\n",
    "        if next_id in (EOS, PAD): break\n",
    "        out_tokens.append(next_id)\n",
    "        ys = torch.cat([ys, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return \" \".join(tgt_itos[t] for t in out_tokens)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for src, tgt_in, tgt_out in loader:\n",
    "        src, tgt_in, tgt_out = src.to(device), tgt_in.to(device), tgt_out.to(device) \n",
    "        logits = model(src,tgt_in)\n",
    "        loss = crit(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"epoch {epoch+1}: loss {running_loss/len(loader):.4f}\")\n",
    "    print(translate(\"I will do my best.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
