{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f82d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1,2,3]) # tensor is n-dimentional array \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5859f964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4196, 0.0964, 0.1988],\n",
       "        [0.3200, 0.4745, 0.0249]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(2,3) #random tensor, 2 rows, 3 columns\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6a79d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(2,3)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db97cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(2,3)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a152a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f05fd4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 22.],\n",
       "        [43., 50.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2], [3,4]])\n",
    "b = torch.tensor([[5.,6], [7,8]])\n",
    "\n",
    "a@b # or torch.matmul(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9d68a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 12],\n",
       "        [21, 32]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elementwise\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e81281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04af030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpu, cuda, mps and possibly other frameworks\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229aad24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradients\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True) #mode: propogate the gradients over all the computation steps\n",
    "y = x**2 + 3*x + 5\n",
    "# 2*x +3 -> 2*2 +3 =7\n",
    "y.backward() #compute gradients using back propagation algorithm \n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b5a1b",
   "metadata": {},
   "source": [
    "- easy Neural Network, one gradient descent step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611831b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2 (before update)\n",
      "Loss: 1.1 (after update)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # Neural Networks \n",
    "import torch.optim as optim # optimizer framework for gradient methods\n",
    "\n",
    "# 10 inouts, 1 output -> fully connected feed-forward neural network\n",
    "NN = nn.Linear(10,1) # Linear is W*x + b, in Tensorflow -> Dense not Linear\n",
    "#MLP -> Multi-Layer Perception\n",
    "# in Literature/Publications: FC(), FFN(feed-forward network), FFNN(feed-forward neural network), MLP\n",
    "\n",
    "loss = nn.MSELoss() # mean squared error\n",
    "# loss, cost, criterion, crit\n",
    "optimizer = optim.SGD(NN.parameters(), lr = 1e-2)\n",
    "# lr = learning rate, eta, alpha\n",
    "# NN.parameters() ... these are our weights and biases\n",
    "\n",
    "input_data = torch.rand(10) # random stuff, X\n",
    "output = NN(input_data) # y_pred, predictions, y_hat\n",
    "y = torch.ones(1) # ground truth, target, regr\n",
    "\n",
    "#initial value of the loss function\n",
    "loss_output = loss(y, output) # Difference between the reality and expectation\n",
    "print(f\"Loss: {loss_output:.2} (before update)\")\n",
    "\n",
    "# two magical lines (no touching these 2 lines)\n",
    "loss_output.backward() #compute gradients\n",
    "optimizer.step() # Update the weights and biases \n",
    "\n",
    "output_new = NN(input_data) # here are new weights and biases \n",
    "loss_new = loss(output_new, y) # value of the loss function after one update\n",
    "print(f\"Loss: {loss_new:.2} (after update)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e27f4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87b5ff07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1091], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output # before update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5836f51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8951], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_new # after update "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6cefb",
   "metadata": {},
   "source": [
    "# FashionMNIST dataset \n",
    "-modern HelloWorld for NNs (by Zalando)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cca94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert to tensor\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c2a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "\n",
    "class NN(nn.Module): # class\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__() # init from the superclass\n",
    "        self.layer1 = nn.Linear(28*28, 128) # input layer (should take the pictures and do something with them)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.layer2 = nn.Linear(128, 64) # hidden layer (neither input nor output layer, the intermediate layer beasically)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.layer3 = nn.Linear(64, 10) #output layer, 10 number of product categories\n",
    "        self.drop = nn.Dropout(0.3) # 30% of activations are set to zero\n",
    "        #when using dropout, theres no point in using 0.15, just use increments of 0.1 -> 0.2 -> ... -> 0.5\n",
    "\n",
    "        # First way to apply BatchNorm (preactivation)\n",
    "\n",
    "    def forward(self,x): # propagate the information through the network \n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D\n",
    "        x = torch.relu(self.bn1(self.layer1(x))) # activation using ReLU \n",
    "        x = self.drop(x) # dropout can also be put here. dont put dopout for input layer because you want all input neurons. \n",
    "        x = torch.relu(self.bn2(self.layer2(x)))\n",
    "        x = self.drop(x) # dropout is usually placed here\n",
    "        x = self.layer3(x) # indentity activation -> logit (no need to compute gradients of softmax)\n",
    "        return x\n",
    "    \n",
    "        # Second way to apply BatchNorm (Postactivation)\n",
    "\n",
    "    def forward(self,x): # propagate the information through the network \n",
    "        x = x.view(-1, 28*28) # flatten 2D -> 1D\n",
    "        x = torch.relu(self.layer1(x)) # activation using ReLU \n",
    "        x = self.bn1(x)\n",
    "        x = self.drop(x) # dropout can also be put here. dont put dopout for input layer because you want all input neurons. \n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.drop(x) # dropout is usually placed here\n",
    "        x = self.layer3(x) # indentity activation -> logit (no need to compute gradients of softmax)\n",
    "        return x\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e174c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/40], Loss: 1164.992919921875\n",
      "Epoch[2/40], Loss: 781.4962158203125\n",
      "Epoch[3/40], Loss: 663.2780151367188\n",
      "Epoch[4/40], Loss: 596.8756713867188\n",
      "Epoch[5/40], Loss: 553.795654296875\n",
      "Epoch[6/40], Loss: 527.2633056640625\n",
      "Epoch[7/40], Loss: 505.00341796875\n",
      "Epoch[8/40], Loss: 489.5926818847656\n",
      "Epoch[9/40], Loss: 475.85858154296875\n",
      "Epoch[10/40], Loss: 465.38946533203125\n",
      "Epoch[11/40], Loss: 454.567626953125\n",
      "Epoch[12/40], Loss: 444.9560241699219\n",
      "Epoch[13/40], Loss: 436.3873596191406\n",
      "Epoch[14/40], Loss: 427.5809631347656\n",
      "Epoch[15/40], Loss: 420.22052001953125\n",
      "Epoch[16/40], Loss: 416.5887756347656\n",
      "Epoch[17/40], Loss: 410.8335266113281\n",
      "Epoch[18/40], Loss: 404.0298767089844\n",
      "Epoch[19/40], Loss: 403.4423828125\n",
      "Epoch[20/40], Loss: 394.0428161621094\n",
      "Epoch[21/40], Loss: 393.3251953125\n",
      "Epoch[22/40], Loss: 386.9781799316406\n",
      "Epoch[23/40], Loss: 383.8389587402344\n",
      "Epoch[24/40], Loss: 380.0873107910156\n",
      "Epoch[25/40], Loss: 376.14105224609375\n",
      "Epoch[26/40], Loss: 373.02337646484375\n",
      "Epoch[27/40], Loss: 371.50299072265625\n",
      "Epoch[28/40], Loss: 369.77935791015625\n",
      "Epoch[29/40], Loss: 369.50164794921875\n",
      "Epoch[30/40], Loss: 363.0328063964844\n",
      "Epoch[31/40], Loss: 360.2625732421875\n",
      "Epoch[32/40], Loss: 360.4505920410156\n",
      "Epoch[33/40], Loss: 355.2521057128906\n",
      "Epoch[34/40], Loss: 354.8380126953125\n",
      "Epoch[35/40], Loss: 350.53607177734375\n",
      "Epoch[36/40], Loss: 347.5938720703125\n",
      "Epoch[37/40], Loss: 348.1783447265625\n",
      "Epoch[38/40], Loss: 346.5121765136719\n",
      "Epoch[39/40], Loss: 343.4915466308594\n",
      "Epoch[40/40], Loss: 342.0711364746094\n"
     ]
    }
   ],
   "source": [
    "# Now training \n",
    "\n",
    "model = NN()\n",
    "lr = 1e-3 # learning rate \n",
    "loss = nn.CrossEntropyLoss() # CE because multi-class problem \n",
    "optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "\n",
    "n_epochs = 40 \n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train() # train mode\n",
    "    running_loss = 0.0 # loss per epoch \n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # reset the gradients \n",
    "        # forward\n",
    "        outputs = model(images) # calculate outputs\n",
    "        curr_loss = loss(outputs, labels)\n",
    "        running_loss += curr_loss\n",
    "        # backward\n",
    "        curr_loss.backward() # gradients\n",
    "        optimizer.step() # update weights and biases\n",
    "    print(f\"Epoch[{epoch + 1}/{n_epochs}], Loss: {running_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2def1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf558cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db69ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.46%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = torch.max(outputs.data, 1)[-1]\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "        \n",
    "accuracy = correct/total\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
